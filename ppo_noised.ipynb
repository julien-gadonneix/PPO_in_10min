{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "import torch\n",
    "from src.trainer import Trainer\n",
    "from src.models import NN_CartPole, NN_Humanoid, NN_Hopper\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_env = \"Humanoid-v5\"\n",
    "str_env = \"Hopper-v5\"\n",
    "# str_env = \"CartPole-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations and initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = {\"CartPole-v1\": 100, \"Humanoid-v5\": 1000, \"Hopper-v5\": 600}\n",
    "epochs = {\"CartPole-v1\": 8, \"Humanoid-v5\": 8, \"Hopper-v5\": 12} # Hopper-v5: [8, 12, 16]\n",
    "N = {\"CartPole-v1\": 4, \"Humanoid-v5\": 4, \"Hopper-v5\": 4} # Hopper-v5: [2, 4, 6]\n",
    "T = {\"CartPole-v1\": 256, \"Humanoid-v5\": 256, \"Hopper-v5\": 1024} # Hopper-v5: [512, 1024, 2048]\n",
    "batches = {\"CartPole-v1\": 4, \"Humanoid-v5\": 4, \"Hopper-v5\": 4}\n",
    "value_loss_coef = {\"CartPole-v1\": 0.5, \"Humanoid-v5\": 0.5, \"Hopper-v5\": 1.0}\n",
    "entropy_bonus_coef = {\"CartPole-v1\": 1e-3, \"Humanoid-v5\": 1e-3, \"Hopper-v5\": 5e-5} # Hopper-v5: [1e-5, 5e-5, 1e-4]\n",
    "clip_range = {\"CartPole-v1\": 0.1, \"Humanoid-v5\": 0.1, \"Hopper-v5\": 0.1}\n",
    "learning_rate = {\"CartPole-v1\": 1e-3, \"Humanoid-v5\": 1e-3, \"Hopper-v5\": 1e-4} # Hopper-v5: [1e-5, 1e-4, 1e-3]\n",
    "learning_rate_decay = {\"CartPole-v1\": 0.999, \"Humanoid-v5\": 0.999, \"Hopper-v5\": 0.999}\n",
    "reward_scaling = {\"CartPole-v1\": 1.0, \"Humanoid-v5\": 0.005, \"Hopper-v5\": 0.1}\n",
    "models = {\"CartPole-v1\": NN_CartPole, \"Humanoid-v5\": NN_Humanoid, \"Hopper-v5\": NN_Hopper}\n",
    "\n",
    "# Configurations\n",
    "configs = {\n",
    "    # Number of updates\n",
    "    'updates': updates[str_env],\n",
    "    # Number of epochs to train the model with sampled data.\n",
    "    'epochs': epochs[str_env],\n",
    "    # Number of worker processes\n",
    "    'N': N[str_env],\n",
    "    # Number of steps to run on each process for a single update\n",
    "    'T': T[str_env],\n",
    "    # Number of mini batches\n",
    "    'batches': batches[str_env],\n",
    "    # Value loss coefficient.\n",
    "    'value_loss_coef': value_loss_coef[str_env],\n",
    "    # Entropy bonus coefficient.\n",
    "    'entropy_bonus_coef': entropy_bonus_coef[str_env],\n",
    "    # Clip range.\n",
    "    'clip_range': clip_range[str_env],\n",
    "    # Learning rate.\n",
    "    'learning_rate': learning_rate[str_env],\n",
    "    # Learning rate decay.\n",
    "    'learning_rate_decay': learning_rate_decay[str_env],\n",
    "    # Model to use\n",
    "    'model': models[str_env](),\n",
    "    # Device to use for training\n",
    "    'device': device,\n",
    "    # Environment to use\n",
    "    'str_env': str_env,\n",
    "    # Reward scaling\n",
    "    'reward_scaling': reward_scaling[str_env]\n",
    "}\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(**configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: load a checkpoint pretrained model and log a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load checkpoint and save video\n",
    "# checkpoint = torch.load(\"checkpoint/\" + str_env + \"_model.pth\", weights_only=True, map_location=device)\n",
    "# trainer.model.load_state_dict(checkpoint)\n",
    "# if device != torch.device(\"cuda:0\") or str_env == \"CartPole-v1\":\n",
    "#     trainer.log_video(str_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log a video example of the noised agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video recorded with duration 300 frames.\n",
      "MoviePy - Building video results/Hopper-v5_noised.mp4.\n",
      "MoviePy - Writing video results/Hopper-v5_noised.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready results/Hopper-v5_noised.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if device != torch.device(\"cuda:0\") or str_env == \"CartPole-v1\":\n",
    "    trainer.log_video_with_noise(str_env, use_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 394/600 [22:06<11:59,  3.50s/it]"
     ]
    }
   ],
   "source": [
    "# Run and monitor the experiment\n",
    "trainer.run_training_loop_with_noise()\n",
    "\n",
    "# Stop the workers\n",
    "trainer.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log a video example of your trained agent and save the model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device != torch.device(\"cuda:0\") or str_env == \"CartPole-v1\":\n",
    "    trainer.log_video_with_noise(str_env + \"_trained\", use_model=True)\n",
    "\n",
    "# Save the model\n",
    "torch.save(trainer.model.state_dict(), \"checkpoint/\" + str_env + \"_model_with_noise.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the plottings for your single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot(str_env + \"_noised\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_ic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
